{
  "hash": "238e1ee559925587a26a52799c867af4",
  "result": {
    "markdown": "---\nformat: \n  revealjs:\n    css: ../../styles.css\n    slide-number: true\n    show-slide-number: all\n    progress: true\n    history: true\n    hash-type: number\n    theme: default\n    code-block-background: true\n    highlight-style: github\n    code-link: false\n    code-copy: true\n    controls: true\n    pagetitle: \"Inter R4SS Day 3B\"\n    author-meta: \"Jeffrey Girard\"\n    date-meta: \"2023-06-07\"\n---\n\n\n::: {.my-title}\n# [Intermediate R]{.blue2} <br />for Social Scientists\n\n::: {.my-grey}\n[Workshop Day 3B | 2023-06-07]{}<br />\n[Jeffrey M. Girard | Pitt Methods]{}\n:::\n\n![](../../img/proud2_2780E3.svg){.absolute bottom=0 right=0 width=400}\n:::\n\n# GLM\n\n## The Linear Model (LM)\n\n$$\n\\begin{align}\n\\mu &= b_0 + b_1 x_{1} + \\cdots + b_m x_{m}\\\\\ny &\\sim \\text{Gaussian}(\\mu, \\sigma)\n\\end{align}\n$$\n\n::: {.fragment .f80}\n\n- The first (structural) term is [linear]{.b .blue} (i.e., the sum of products)\n    -   It assumes that $\\mu_i$ can vary indefinitely, i.e., $y \\in (\\infty,\\infty)$\n    \n:::\n\n::: {.fragment .f80}\n- The second (random) term describes the [shape of the residuals]{.b .blue}\n    -   It assumes they are [normally (Gaussian) distributed]{.b .green} around $\\mu_i$\n    -   It assumes they have [constant variance]{.b .green} (i.e., there is only one $\\sigma$)\n    \n:::\n\n## The Generalized LM (GLM)\n\n::: {.f80}\n- What happens when these assumptions are violated?\n    -   Our parameters and inferences will be biased\n    -   Our model may make impossible predictions\n\n:::\n\n::: {.fragment}\n\n::: {.f80}\n- GLM addresses this issue by making two changes\n    -   Adds a [family]{.b .blue}, i.e., specifies a different shape of the residuals\n    -   Adds a [link function]{.b .green}, i.e., transforms $y$ to vary indefinitely\n\n:::\n\n$$\n\\begin{align}\n\\color{ForestGreen}{\\text{link}}(\\mu) &= b_0 + b_1 x_{1} + \\cdots + b_m x_{m} \\\\\ny &\\sim \\color{blue}{\\text{family}}(\\mu, \\ldots)\n\\end{align}\n$$\n:::\n\n\n## GLM Families\n\n- [Normal:]{.b .green} $y \\in \\mathbb{R}$, use `gaussian()` with identity link\n- [Binary:]{.b .blue} $y \\in \\{0,1\\}$, use `binomial()` with logit/probit link\n- [Counts:]{.b .blue} $y \\in \\{0, 1, 2, ...\\}$, use `poisson()` with log link\n    - (See also Quasipoisson, Binomial, and Negative Binomial)\n\n::: {.fragment .f60 .mt1}\n\n### Advanced GLM Families (note: these may require special packages)\n\n::: {.columns}\n\n::: {.column}\n- **Proportions:** Beta, Dirichlet\n- **Nominal:** Categorical, Multinomial\n- **Ordinal:** Cumulative, Adjacent Category\n:::\n\n::: {.column}\n- **Near Normal:** Student's $t$, Skew-normal\n- **Survival:** Weibull, Cox\n- **Reaction Times:** Exgaussian, Shifted Lognormal\n:::\n\n:::\n:::\n\n## Binary Regression\n\n-   Binary regression is used when $y$ is binary, i.e., $0$ or $1$\n    -   *e.g., healthy or sick, pass or fail, present or absent*\n\n::: {.fragment}\n-   We can use the [Binomial]{.b .blue} family if we set $n=1$\n\n$$\nk \\sim \\text{Binomial}(n,p)\n$$\n\n$n\\in\\{0,1,2,...\\}$ --- the number of trials\n\n$p\\in[0,1]$ --- the probability of success in each trial\n\n$k\\in\\{0,1,...,n\\}$ --- the number of successes\n:::\n\n\n## The Binomial Family\n\n$$\n\\begin{align}\n\\color{red}{\\text{link}}(p) &= b_0 + b_1 x_1 + \\cdots + b_m x_m \\\\\ny &\\sim \\text{Binomial}(1, p)\n\\end{align}\n$$\n\n- Our structural model predicts $p$ (the probability that $y=1$)\n    -   $p$ is continuous but bounded, $p\\in[0,1]$\n    -   But we need it to be unbounded, $(-\\infty,\\infty)$\n    -   We need a link function to do this transformation...\n\n::: {.fragment}\n$$\\text{logit}(p)=\\log(\\text{Odds}(p))=\\log\\left(\\frac{p}{1-p}\\right)$$\n:::\n\n## The Logit Link\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3B_Slides_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n## Binary Regression\n\n$$\n\\begin{align}\n\\text{logit}(p) &= b_0 + b_1 x_1 + \\cdots + b_m x_m \\\\\ny &\\sim \\text{Binomial}(1, p)\n\\end{align}\n$$\n\n::: {.fragment}\n- Our slopes ($b_m$) will be in [logit (log-odd) units]{.b .green}\n    -   $b_m>0$ indicates increased prob., $b_m<0$ decreased\n\n:::\n\n::: {.fragment}\n- We can exponentiate them to convert to [Odds Ratios]{.b .blue}\n    -   If $b_1=0.3$, then $OR=e^{0.3}=1.35$ times the odds of success (or a 35% increase) when increasing $x_1$ by 1\n    -   If $b_1=-0.3$, then $OR=e^{-0.3}=0.74$ times the odds of success (or a 26% decrease) when increasing $x_1$ by 1\n\n:::\n\n## Binary Regression Live Coding\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\n## Load packages (after installing, if needed)\nlibrary(tidyverse)\nlibrary(easystats)\n\n## Read in some example binary data and mutate the outcome to be 0 vs. 1\ntitanic <- \n  read_csv(\"titanic.csv\") |> \n  mutate(survived = if_else(survived == \"yes\", true = 1, false = 0)) |> \n  print()\n\n## Visualize the relationship between fare and survival\nggplot(titanic, aes(x = fare, y = survived)) +\n  geom_point() +\n  geom_smooth()\n\n## Fit a basic regression using LM\nfit <- lm(\n  formula = survived ~ fare, \n  data = titanic\n)\nmodel_parameters(fit)\nmodel_performance(fit)\nplot(estimate_expectation(fit))\ncheck_model(fit)\n\n## Fit a logistic regression using GLM\nfit2 <- glm(\n  formula = survived ~ fare, \n  family = binomial(link = \"logit\"), \n  data = titanic\n)\nmodel_parameters(fit2)\nmodel_parameters(fit2, exponentiate = TRUE)\nmodel_performance(fit2)\nplot(estimate_link(fit2))\nplot(estimate_expectation(fit2))\ncheck_model(fit2)\n\n## Estimate the model's expectation for specific values of the predictor(s)\nestimate_expectation(fit2, tibble(fare = c(10, 50, 100)))\n\n## Note: To fit a probit binary regression, just use binomial(link = \"probit\")\n```\n:::\n\n\n\n## Count Regression\n\n- Count regression is used when $y$ is a [whole number]{.b .green}\n    - e.g., $\\{0,1,2,3,...\\}$ (not negative, fractional, etc.)\n\n::: {.fragment}\n- Counts can be [bounded]{.b .green} (i.e., have a maximum number)\n    - *e.g., how many answers on the test were correct?*\n    - For these, we can re-use the **Binomial** family $(n>0)$\n\n:::\n\n::: {.fragment}\n- Counts can also be [unbounded]{.b .blue} (i.e., no maximum)\n    - *e.g., how many hospitalizations in the last 10 years?*\n    - *e.g., how many social interactions since yesterday?*\n    - For these, we can use **Poisson** or **Negative Binomial**\n    \n:::\n\n\n## Poisson Regression\n\n$$\n\\begin{align}\n\\log(\\mu) &= b_0 + b_1 x_1 + \\cdots + b_m x_m \\\\\ny &\\sim \\text{Poisson}(\\mu)\n\\end{align}\n$$\n\n::: {.fragment}\n- Our slopes ($b_m$) will be in [log units]{.b .green}\n    -   $b_m>0$ indicates increased rate, $b_m<0$  decreased\n\n:::\n\n::: {.fragment}\n- We can exponentiate to convert to [Incidence Rate Ratios]{.b .blue}\n    -   If $b_1=0.3$, then $IRR=e^{0.3}=1.35$ times the incidence rate (a 35% increase) when increasing $x_1$ by 1\n    -   If $b_1=-0.3$, then $IRR=e^{-0.3}=0.74$ times the incidence rate (a 26% decrease) when increasing $x_1$ by 1\n\n:::\n\n\n## Count Regression Live Coding\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"false\"}\n# Read in some example count data\ndisc <- read_csv(\"discoveries.csv\")\ndisc\n\n# Visualize the relationship between year and discovery count\nggplot(disc, aes(x = year, y = count)) + \n  geom_point() +\n  geom_smooth()\n\n# Fit a linear regression using LM\nfit <- lm(\n  formula = count ~ poly(year, degree = 2), \n  data = disc\n)\nmodel_parameters(fit)\nmodel_performance(fit)\nplot(estimate_relation(fit))\ncheck_model(fit)\n\n# Fit a poisson regression using GLM\nfit2 <- glm(\n  formula = count ~ poly(year, degree = 2),\n  family = poisson(link = \"log\"), \n  data = disc\n)\nmodel_parameters(fit2)\nmodel_parameters(fit2, exponentiate = TRUE)\nmodel_performance(fit2)\nplot(estimate_relation(fit2))\ncheck_overdispersion(fit2)\n\n# Due to over-dispersion, fit quasi-poisson using GLM\nfit3 <- glm(\n  count ~ poly(year, degree = 2), \n  family = quasipoisson(link = \"log\"), \n  data = disc\n)\nmodel_parameters(fit3)\nmodel_parameters(fit3, exponentiate = TRUE)\nplot(estimate_relation(fit3))\n\n# Compare parameters between poisson and quasi-poisson\ncompare_parameters(fit2, fit3, select = \"ci_p2\")\n```\n:::\n\n\n# MLM\n\n## Conceptual Overview\n\n## Cluster-Robust Standard Errors\n\n## Random Intercepts\n\n## Fixed Predictors\n\n## Random Effects\n\n## Cross-level Interactions\n\n## Comparing Models\n\n## Repeated/Longitudinal Data\n\n## Centering and Disaggregating\n\n## Effect Sizes\n\n",
    "supporting": [
      "3B_Slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}