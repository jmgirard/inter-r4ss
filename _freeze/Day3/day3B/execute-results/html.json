{
  "hash": "f45471169d9e1b2545f94923121c72c4",
  "result": {
    "markdown": "---\ntitle: \"Day 3B\"\nformat:\n  html:\n    css: ../styles.css\n    highlight-style: github\n---\n\n\n![](../img/analytics_2780E3.svg){.hero}\n\n\nWe conclude the workshop with a discussion of intermediate statistical modeling techniques in R. We will be able to use the same R formulas and \\{easystats\\} functions taught in the introductory workshop to extend the linear model to the generalized linear model (allowing us to model non-normal outcome variables) and linear mixed-effects/multilevel models (allowing us to model data with a clustered or hierarchical structure).\n\n## Slides\n\n<iframe class=\"slide-deck\" src=\"./Slides/3B_Slides.html\" title=\"Day 3B Slideshow\">\n</iframe>\n\n[Click here to view the slides in their own window.](./Slides/3B_Slides.html)\n\n## Data Files\n\n- <a href=\"titanic.csv\" download=\"titanic.csv\">titanic</a> (data about passengers on the Titanic including survival)\n- <a href=\"discoveries.csv\" download=\"discoveries.csv\">discoveries</a> (number of scientific discoveries per year)\n- <a href=\"mlmath.csv\" download=\"mlmath.csv\">mlmath</a> (academic data from students clustered within schools)\n- <a href=\"soccer.csv\" download=\"soccer.csv\">soccer</a> (hormone data measured longitudinally from soccer players)\n\n## Practice 1\n\na) Download the *titanic* dataset linked above and read it into R. Tidy it if needed to prepare to run a logistic regression predicting the `survived` variable (*hint:* tidying is needed). \nb) Fit a logistic regression (using `glm()`) to predict the `survived` variable from the `age`, `sex`, and `class` variables.\nc) Look at the model parameters estimates. Was being in 2nd class associated with a higher or lower probability of survival than being in 1st class? Was this difference significant?\nd) What was the Odds Ratio for the effect from part (c)?\ne) Plot the model expectations. Based on this plot, who was more likely to survive: men from 1st class or women from 3rd class?\n\n<p><details>\n<summary>Click here for the answer key</summary>\n<blockquote>\n\n**Answer (a)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n\ntitanic <- \n  read_csv(\"titanic.csv\") |> \n  mutate(survived = if_else(survived == \"yes\", true = 1, false = 0))\n```\n:::\n\n\n**Answer (b)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- glm(\n  formula = survived ~ age + sex + class, \n  family = binomial(link = \"logit\"), \n  data = titanic\n)\n```\n:::\n\n\n**Answer (c)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit1) |> print_md()\n```\n\n::: {.cell-output-display}\n|Parameter   | Log-Odds |       SE |         95% CI |      z |      p |\n|:-----------|:--------:|:--------:|:--------------:|:------:|:------:|\n|(Intercept) |     3.63 |     0.37 |   (2.93, 4.38) |   9.81 | < .001 |\n|age         |    -0.03 | 7.16e-03 | (-0.05, -0.02) |  -4.79 | < .001 |\n|sex (male)  |    -2.59 |     0.19 | (-2.96, -2.23) | -13.84 | < .001 |\n|class (2nd) |    -1.20 |     0.26 | (-1.72, -0.69) |  -4.58 | < .001 |\n|class (3rd) |    -2.46 |     0.25 | (-2.96, -1.97) |  -9.70 | < .001 |\n:::\n:::\n\n\nBecause the slope of \"class (2nd)\" is negative---in logit units---this means that being in 2nd class is associated with a lower probability of surviving than the reference group of \"class (1st).\" Because $p<.001$, this effect is significant. \n\n**Answer (d)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit1, exponentiate = TRUE) |> print_md()\n```\n\n::: {.cell-output-display}\n|Parameter   | Odds Ratio |       SE |         95% CI |      z |      p |\n|:-----------|:----------:|:--------:|:--------------:|:------:|:------:|\n|(Intercept) |      37.90 |    14.04 | (18.69, 79.95) |   9.81 | < .001 |\n|age         |       0.97 | 6.92e-03 |   (0.95, 0.98) |  -4.79 | < .001 |\n|sex (male)  |       0.08 |     0.01 |   (0.05, 0.11) | -13.84 | < .001 |\n|class (2nd) |       0.30 |     0.08 |   (0.18, 0.50) |  -4.58 | < .001 |\n|class (3rd) |       0.09 |     0.02 |   (0.05, 0.14) |  -9.70 | < .001 |\n:::\n:::\n\n\nThe odds ratio is this effect is 0.30.\n\n**Answer (e)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(estimate_expectation(fit1))\n```\n\n::: {.cell-output-display}\n![](day3B_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nBecause the (dashed red) line for women in 3rd class is higher than the (blue solid) line for men in 1st class, the former were more likely to survive.\n\n</blockquote></details></p>\n\n## Practice 2\n\na) Download the *mlmath* dataset linked above and read it into R. Tidy it if needed to prepare to run a multilevel regression predicting the `math` variable. \nb) Fit a null model that accounts for the clustering of students within schools. What was the multilevel ICC for `math`?\nc) Fit a random intercept and slope model that predicts `math` from each student's `homework` while controlling for that student's `sex` and whether their school is `public` or not. Is the fixed effect of `homework` significant?\nd) Estimate the group-level effects from this model and plot them. How many schools have a positive slope?\n\n<p><details>\n<summary>Click here for the answer key</summary>\n<blockquote>\n\n**Answer (a)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\n\nmlmath <- \n  read_csv(\"mlmath.csv\") |> \n  mutate(across(c(student, sex, public), factor))\n```\n:::\n\n\nNo tidying is strictly necessary here, but setting up factors is good practice.\n\n**Answer (b)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2b <- lmer(\n  math ~ 1 + (1 | school),\n  data = mlmath\n)\nmodel_performance(fit2b) |> print_md()\n```\n\n::: {.cell-output-display}\nTable: Indices of model performance\n\n|AIC     |    AICc |     BIC | R2 (cond.) | R2 (marg.) |  ICC | RMSE | Sigma |\n|:-------|:-------:|:-------:|:----------:|:----------:|:----:|:----:|:-----:|\n|1877.68 | 1877.77 | 1888.36 |       0.32 |       0.00 | 0.32 | 8.35 |  8.50 |\n:::\n:::\n\n\nThe multilevel ICC for `math` is 0.32, i.e., 32\\% of the variance is explained by differences between schools.\n\n**Answer (c)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2c <- lmer(\n  math ~ 1 + homework + sex + public + (1 + homework | school),\n  data = mlmath\n)\nmodel_parameters(fit2c) |> print_md()\n```\n\n::: {.cell-output-display}\nTable: # Fixed Effects\n\n|Parameter       | Coefficient |   SE |           95% CI | t(252) |      p |\n|:---------------|:-----------:|:----:|:----------------:|:------:|:------:|\n|(Intercept)     |       57.70 | 3.00 |   (51.80, 63.61) |  19.24 | < .001 |\n|homework        |        1.98 | 1.60 |    (-1.17, 5.13) |   1.24 | 0.216  |\n|sex [male]      |        0.56 | 0.84 |    (-1.08, 2.21) |   0.67 | 0.501  |\n|public [public] |      -14.66 | 2.12 | (-18.84, -10.47) |  -6.90 | < .001 |\n\nTable: # Random Effects\n\n|Parameter                        | Coefficient |   SE |        95% CI |\n|:--------------------------------|:-----------:|:----:|:-------------:|\n|SD (Intercept: school)           |        6.79 | 1.82 | (4.01, 11.48) |\n|SD (homework: school)            |        4.90 | 1.23 |  (2.99, 8.02) |\n|Cor (Intercept~homework: school) |       -0.97 | 0.51 | (-1.00, 1.00) |\n|SD (Residual)                    |        6.56 | 0.30 |  (6.00, 7.18) |\n:::\n:::\n\n\nThe fixed effect of `homework` was 1.98 but was not significant, $p=.216$.\n\n**Answer (d)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_grouplevel(fit2c) |> plot()\n```\n\n::: {.cell-output-display}\n![](day3B_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nIt looks like five of the ten schools (i.e., half) had positive homework slopes.\n\n</blockquote></details></p>\n\n## Challenge 1\n\na) Add a new (binary) variable to the *mlmath* dataset that is $1$ if `math` > 50 and is $0$ otherwise.\n\nb) Combine what you learned from the GLM and MLM lectures to create a generalized linear mixed model (GLMM) that predicts this new binary variable from the `homework` and `public` variables while estimating random effects clustered by `school`. You will need to use the `glmer()` function from \\{lme4\\} and provide it a family and link function. You can use the same family and link function we used before for standard logistic regression!\n\nc) Estimate this model's parameters. Which fixed effects are significant, if any?\n\nd) Plot this model's predictions. What did you learn from this plot?\n\n<p><details>\n<summary>Click here for the answer key</summary>\n<blockquote>\n\n**Answer (a)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmath_challenge <-\n  mlmath |> \n  mutate(math_pass = if_else(math > 50, true = 1, false = 0))\n```\n:::\n\n\n**Answer (b)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- glmer(\n  math_pass ~ 1 + homework + public + (1 + homework | school),\n  data = math_challenge,\n  family = binomial(link = \"logit\")\n)\n```\n:::\n\n\n**Answer (c)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(fit) |> print_md()\n```\n\n::: {.cell-output-display}\nTable: # Fixed Effects\n\n|Parameter       | Log-Odds |   SE |         95% CI |     z |      p |\n|:---------------|:--------:|:----:|:--------------:|:-----:|:------:|\n|(Intercept)     |     3.10 | 1.40 |   (0.35, 5.85) |  2.21 | 0.027  |\n|homework        |     0.61 | 0.52 |  (-0.40, 1.62) |  1.18 | 0.238  |\n|public [public] |    -5.29 | 1.30 | (-7.83, -2.75) | -4.08 | < .001 |\n\nTable: # Random Effects\n\n|Parameter                        | Coefficient |   SE |         95% CI |\n|:--------------------------------|:-----------:|:----:|:--------------:|\n|SD (Intercept: school)           |        1.95 | 0.62 |   (1.04, 3.62) |\n|SD (homework: school)            |        1.46 | 0.45 |   (0.80, 2.69) |\n|Cor (Intercept~homework: school) |       -0.97 | 0.04 | (-1.00, -0.59) |\n:::\n:::\n\n\nThe fixed effect of `public` is significantly negative and thus students from public schools were less likely to score higher than 50 on `math` than students from non-public schools. The fixed intercept was also significant, but that is less interesting.\n\n**Answer (d)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimate_relation(fit) |> plot()\n```\n\n::: {.cell-output-display}\n![](day3B_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThis is a cool plot. It looks like students at non-public schools were very likely to score higher than 50 on `math` regardless of the amount of homework they did, whereas students at public schools became more likely to do so when they did more homework. We do need to be careful about this conclusion however, because this model did not explicitly test the homework-by-public interaction. So we would need to follow up on this hypothesis with more testing.\n\n</blockquote></details></p>\n\n## Challenge 2\n\nDownload the *soccer* dataset linked above and read it into R. Tidy it if needed. Examine the variables and come up with a few research questions to explore using multilevel modeling. Perhaps see if being on birth control (`HormonCont`) was associated with `Testosterone` or `Cortisol`, etc. Be sure to control for time (`time0`) in your models.\n\n## Readings\n\n- [Chapter 8: Generalized Linear Models](https://bookdown.org/steve_midway/DAR/glms-generalized-linear-models.html) in *DAR*\n- [Chapter 9: Random Effects](https://bookdown.org/steve_midway/DAR/random-effects.html) in *DAR*\n- [Chapters 4--12](https://www.learn-mlms.com/) in *IMM*\n\n",
    "supporting": [
      "day3B_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}