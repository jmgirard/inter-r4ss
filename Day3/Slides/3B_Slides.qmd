---
format: 
  revealjs:
    css: ../../styles.css
    slide-number: true
    show-slide-number: all
    progress: true
    history: true
    hash-type: number
    theme: default
    code-block-background: true
    highlight-style: github
    code-link: false
    code-copy: true
    controls: true
    pagetitle: "Inter R4SS Day 3B"
    author-meta: "Jeffrey Girard"
    date-meta: "2023-06-07"
---

::: {.my-title}
# [Intermediate R]{.blue2} <br />for Social Scientists

::: {.my-grey}
[Workshop Day 3B | 2023-06-07]{}<br />
[Jeffrey M. Girard | Pitt Methods]{}
:::

![](../../img/proud2_2780E3.svg){.absolute bottom=0 right=0 width=400}
:::

# GLM

## The Linear Model (LM)

$$
\begin{align}
\mu &= b_0 + b_1 x_{1} + \cdots + b_m x_{m}\\
y &\sim \text{Gaussian}(\mu, \sigma)
\end{align}
$$

::: {.fragment .f80}

- The first (structural) term is [linear]{.b .blue} (i.e., the sum of products)
    -   It assumes that $\mu_i$ can vary indefinitely, i.e., $y \in (\infty,\infty)$
    
:::

::: {.fragment .f80}
- The second (random) term describes the [shape of the residuals]{.b .blue}
    -   It assumes they are [normally (Gaussian) distributed]{.b .green} around $\mu_i$
    -   It assumes they have [constant variance]{.b .green} (i.e., there is only one $\sigma$)
    
:::

## The Generalized LM (GLM)

::: {.f80}
- What happens when these assumptions are violated?
    -   Our parameters and inferences will be biased
    -   Our model may make impossible predictions

:::

::: {.fragment}

::: {.f80}
- GLM addresses this issue by making two changes
    -   Adds a [family]{.b .blue}, i.e., specifies a different shape of the residuals
    -   Adds a [link function]{.b .green}, i.e., transforms $y$ to vary indefinitely

:::

$$
\begin{align}
\color{ForestGreen}{\text{link}}(\mu) &= b_0 + b_1 x_{1} + \cdots + b_m x_{m} \\
y &\sim \color{blue}{\text{family}}(\mu, \ldots)
\end{align}
$$
:::


## GLM Families

- [Normal:]{.b .green} $y \in \mathbb{R}$, use `gaussian()` with identity link
- [Binary:]{.b .blue} $y \in \{0,1\}$, use `binomial()` with logit/probit link
- [Counts:]{.b .blue} $y \in \{0, 1, 2, ...\}$, use `poisson()` with log link
    - (See also Quasipoisson, Binomial, and Negative Binomial)

::: {.fragment .f60 .mt1}

### Advanced GLM Families (note: these may require special packages)

::: {.columns}

::: {.column}
- **Proportions:** Beta, Dirichlet
- **Nominal:** Categorical, Multinomial
- **Ordinal:** Cumulative, Adjacent Category
:::

::: {.column}
- **Near Normal:** Student's $t$, Skew-normal
- **Survival:** Weibull, Cox
- **Reaction Times:** Exgaussian, Shifted Lognormal
:::

:::
:::

## Binary Regression

-   Binary regression is used when $y$ is binary, i.e., $0$ or $1$
    -   *e.g., healthy or sick, pass or fail, present or absent*

::: {.fragment}
-   We can use the [Binomial]{.b .blue} family if we set $n=1$

$$
k \sim \text{Binomial}(n,p)
$$

$n\in\{0,1,2,...\}$ --- the number of trials

$p\in[0,1]$ --- the probability of success in each trial

$k\in\{0,1,...,n\}$ --- the number of successes
:::


## The Binomial Family

$$
\begin{align}
\color{red}{\text{link}}(p) &= b_0 + b_1 x_1 + \cdots + b_m x_m \\
y &\sim \text{Binomial}(1, p)
\end{align}
$$

- Our structural model predicts $p$ (the probability that $y=1$)
    -   $p$ is continuous but bounded, $p\in[0,1]$
    -   But we need it to be unbounded, $(-\infty,\infty)$
    -   We need a link function to do this transformation...

::: {.fragment}
$$\text{logit}(p)=\log(\text{Odds}(p))=\log\left(\frac{p}{1-p}\right)$$
:::

## The Logit Link

```{r}
#| echo: false
#| message: false

library(tidyverse)
tibble(
  p = seq(0.001, 0.999, by = 0.001),
  `logit(p)` = log(p / (1 - p))
) |> 
  ggplot(aes(y = p, x = `logit(p)`)) +
  geom_vline(
    color = "white", 
    linewidth = 4, 
    xintercept = 0
  ) +
  geom_line(color = "royalblue", linewidth = 2) +
  scale_x_continuous(breaks = seq(-6, 6, 2)) +
  theme_gray(base_size = 24) +
  theme(panel.grid.minor = element_blank())

```


## Binary Regression

$$
\begin{align}
\text{logit}(p) &= b_0 + b_1 x_1 + \cdots + b_m x_m \\
y &\sim \text{Binomial}(1, p)
\end{align}
$$

::: {.fragment}
- Our slopes ($b_m$) will be in [logit (log-odd) units]{.b .green}
    -   $b_m>0$ indicates increased prob., $b_m<0$ decreased

:::

::: {.fragment}
- We can exponentiate them to convert to [Odds Ratios]{.b .blue}
    -   If $b_1=0.3$, then $OR=e^{0.3}=1.35$ times the odds of success (or a 35% increase) when increasing $x_1$ by 1
    -   If $b_1=-0.3$, then $OR=e^{-0.3}=0.74$ times the odds of success (or a 26% decrease) when increasing $x_1$ by 1

:::

## Binary Regression Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

## Load packages (after installing, if needed)
library(tidyverse)
library(easystats)

## Read in some example binary data and mutate the outcome to be 0 vs. 1
titanic <- 
  read_csv("titanic.csv") |> 
  mutate(survived = if_else(survived == "yes", true = 1, false = 0)) |> 
  print()

## Visualize the relationship between fare and survival
ggplot(titanic, aes(x = fare, y = survived)) +
  geom_point() +
  geom_smooth()

## Fit a basic regression using LM
fit <- lm(
  formula = survived ~ fare, 
  data = titanic
)
model_parameters(fit)
model_performance(fit)
plot(estimate_expectation(fit))
check_model(fit)

## Fit a logistic regression using GLM
fit2 <- glm(
  formula = survived ~ fare, 
  family = binomial(link = "logit"), 
  data = titanic
)
model_parameters(fit2)
model_parameters(fit2, exponentiate = TRUE)
model_performance(fit2)
plot(estimate_link(fit2))
plot(estimate_expectation(fit2))
check_model(fit2)

## Estimate the model's expectation for specific values of the predictor(s)
estimate_expectation(fit2, tibble(fare = c(10, 50, 100)))

## Note: To fit a probit binary regression, just use binomial(link = "probit")
```


## Count Regression

- Count regression is used when $y$ is a [whole number]{.b .green}
    - e.g., $\{0,1,2,3,...\}$ (not negative, fractional, etc.)

::: {.fragment}
- Counts can be [bounded]{.b .green} (i.e., have a maximum number)
    - *e.g., how many answers on the test were correct?*
    - For these, we can re-use the **Binomial** family $(n>0)$

:::

::: {.fragment}
- Counts can also be [unbounded]{.b .blue} (i.e., no maximum)
    - *e.g., how many hospitalizations in the last 10 years?*
    - *e.g., how many social interactions since yesterday?*
    - For these, we can use **Poisson** or **Negative Binomial**
    
:::


## Poisson Regression

$$
\begin{align}
\log(\mu) &= b_0 + b_1 x_1 + \cdots + b_m x_m \\
y &\sim \text{Poisson}(\mu)
\end{align}
$$

::: {.fragment}
- Our slopes ($b_m$) will be in [log units]{.b .green}
    -   $b_m>0$ indicates increased rate, $b_m<0$  decreased

:::

::: {.fragment}
- We can exponentiate to convert to [Incidence Rate Ratios]{.b .blue}
    -   If $b_1=0.3$, then $IRR=e^{0.3}=1.35$ times the incidence rate (a 35% increase) when increasing $x_1$ by 1
    -   If $b_1=-0.3$, then $IRR=e^{-0.3}=0.74$ times the incidence rate (a 26% decrease) when increasing $x_1$ by 1

:::


## Count Regression Live Coding

```{r}
#| echo: true
#| eval: false
#| error: true
#| code-line-numbers: false

# Read in some example count data
disc <- read_csv("discoveries.csv")
disc

# Visualize the relationship between year and discovery count
ggplot(disc, aes(x = year, y = count)) + 
  geom_point() +
  geom_smooth()

# Fit a linear regression using LM
fit <- lm(
  formula = count ~ poly(year, degree = 2), 
  data = disc
)
model_parameters(fit)
model_performance(fit)
plot(estimate_relation(fit))
check_model(fit)

# Fit a poisson regression using GLM
fit2 <- glm(
  formula = count ~ poly(year, degree = 2),
  family = poisson(link = "log"), 
  data = disc
)
model_parameters(fit2)
model_parameters(fit2, exponentiate = TRUE)
model_performance(fit2)
plot(estimate_relation(fit2))
check_overdispersion(fit2)

# Due to over-dispersion, fit quasi-poisson using GLM
fit3 <- glm(
  count ~ poly(year, degree = 2), 
  family = quasipoisson(link = "log"), 
  data = disc
)
model_parameters(fit3)
model_parameters(fit3, exponentiate = TRUE)
plot(estimate_relation(fit3))

# Compare parameters between poisson and quasi-poisson
compare_parameters(fit2, fit3, select = "ci_p2")
```

# MLM

## Conceptual Overview

## Cluster-Robust Standard Errors

## Random Intercepts

## Fixed Predictors

## Random Effects

## Cross-level Interactions

## Comparing Models

## Repeated/Longitudinal Data

## Centering and Disaggregating

## Effect Sizes

